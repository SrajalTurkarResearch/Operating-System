{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering Storage in Operating Systems: Disk Partitioning and RAID Levels for Aspiring Scientists\n",
    "\n",
    "Dear Aspiring Scientist,\n",
    "\n",
    "Welcome to your definitive guide to storage in operating systems, a cornerstone for researchers handling data in fields like genomics, astrophysics, or AI. Like Alan Turing decoding computation, Albert Einstein unraveling relativity, or Nikola Tesla harnessing electricity, you're building a foundation to safeguard your discoveries. This Jupyter Notebook is a world-class resource, assuming no prior knowledge, and covers **disk partitioning** and **RAID levels** comprehensively. It includes detailed theory, practical code, visualizations, real-world applications, research directions, and projects to propel your scientific career.\n",
    "\n",
    "You mentioned previous tutorials felt like \"upper-layer ideas\" lacking depth, especially in RAID theory. This notebook dives deep into data distribution, parity calculations, and recovery, with practical examples, math derivations, and interdisciplinary connections. It’s structured for note-taking, experimentation, and application in research, ensuring you can rely solely on this resource.\n",
    "\n",
    "**Structure**:\n",
    "1. **Introduction to Storage in OS** – Foundations of storage systems.\n",
    "2. **Disk Partitioning** – Logical organization of physical drives.\n",
    "3. **RAID Levels** – In-depth theory, math, and recovery mechanisms.\n",
    "4. **Advanced Topics for Researchers** – Scientific applications and trends.\n",
    "5. **Tools and Practical Setup** – Hands-on implementation.\n",
    "6. **Mini and Major Projects** – Real-world research applications.\n",
    "7. **Additional Topics and Research Directions** – Missing concepts and future trends.\n",
    "\n",
    "Use this notebook in a Linux environment (e.g., Ubuntu VM) or Jupyter with Python 3. Run code cells, sketch visualizations, and work through exercises. Let’s build your storage expertise to power your scientific journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Storage in Operating Systems\n",
    "\n",
    "### 1.1 What is Storage?\n",
    "Storage is the component of a computer that retains data persistently, unlike **RAM (Random Access Memory)**, which is volatile and loses data when powered off. In an OS (Windows, Linux, macOS), storage encompasses hardware (e.g., HDDs, SSDs) and software (e.g., file systems) to manage data saving, retrieval, and organization.\n",
    "\n",
    "**Theory**:\n",
    "- **Storage Hierarchy**:\n",
    "  - **RAM**: Fast (~GB/s), volatile, for active processes (e.g., running simulations).\n",
    "  - **Cache**: Ultra-fast (~10s GB/s), tiny (MBs), between CPU and RAM.\n",
    "  - **Secondary Storage (Disks)**: Slower (~100s MB/s), persistent, for long-term data.\n",
    "  - **File System**: Organizes data into files/directories, manages metadata (e.g., permissions). Examples:\n",
    "    - **NTFS** (Windows): Supports encryption, large files.\n",
    "    - **ext4** (Linux): Journaling for crash recovery.\n",
    "    - **APFS** (macOS): Optimized for SSDs.\n",
    "- **OS Role**: Manages storage via drivers, ensuring efficient I/O (input/output).\n",
    "\n",
    "**Analogy**: Storage is your lab archive. RAM is a workbench for active experiments; disks are locked cabinets preserving results; the file system is a catalog.\n",
    "\n",
    "**Real-World Example**: In genomics, store terabytes of sequencing data on SSDs; RAM handles real-time analysis, but disks ensure permanence.\n",
    "\n",
    "**Math Insight**:\n",
    "- Capacity: 1 KB = 2^10 bytes = 1024 bytes; 1 GB = 2^30 bytes. For a dataset generating d GB/day over t days, with b% overhead:\n",
    "  ```python\n",
    "  total_needed = (d * t) * (1 + b/100)\n",
    "  ```\n",
    "- Example: d=3, t=120, b=20: total = 3 * 120 * 1.2 = 432 GB.\n",
    "\n",
    "**Visualization**: Sketch a pyramid:\n",
    "```\n",
    "Top: RAM (Speed: ~GB/s, Volatile, Capacity: GBs)\n",
    "Middle: Cache (Speed: 10s GB/s, Tiny: MBs)\n",
    "Bottom: Disk (Speed: 100s MB/s, Persistent, Capacity: TBs+)\n",
    "```\n",
    "**Drawing Steps**:\n",
    "1. Draw a triangle with three layers.\n",
    "2. Label each layer with speed, volatility, capacity.\n",
    "3. Add arrows: RAM -> Disk (saving), Disk -> RAM (loading).\n",
    "4. Note: 'Disks hold research data; RAM for active work.'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate storage needs\n",
    "def calculate_storage(daily_output, days, overhead_percent):\n",
    "    total = daily_output * days\n",
    "    total_with_overhead = total * (1 + overhead_percent / 100)\n",
    "    return total_with_overhead\n",
    "\n",
    "daily = 3  # GB/day\n",
    "days = 120\n",
    "overhead = 20  # %\n",
    "needed = calculate_storage(daily, days, overhead)\n",
    "print(f'Total storage needed: {needed:.2f} GB')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ["Total storage needed: 432.00 GB\n"]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Types of Storage Devices\n",
    "\n",
    "**Hard Disk Drives (HDDs)**:\n",
    "- **Mechanism**: Spinning platters (5400-7200 RPM), magnetic heads read/write data.\n",
    "- **Pros**: Cost-effective (~$0.02/GB in 2025).\n",
    "- **Cons**: Mechanical, prone to vibration failures.\n",
    "- **Speed**: 100-200 MB/s.\n",
    "\n",
    "**Solid-State Drives (SSDs)**:\n",
    "- **Mechanism**: NAND flash chips; electronic storage.\n",
    "- **Pros**: Fast (500-7000 MB/s with NVMe), durable.\n",
    "- **Cons**: Wear-limited (TBW, e.g., 600 TB written).\n",
    "\n",
    "**Cloud Storage**:\n",
    "- **Mechanism**: Remote servers (e.g., AWS S3).\n",
    "- **Pros**: Scalable, accessible.\n",
    "- **Cons**: Latency, costs (~$0.023/GB/month).\n",
    "\n",
    "**Analogy**: HDDs: Analog record players (mechanical, slow); SSDs: Digital streaming (fast); cloud: Online library.\n",
    "\n",
    "**Real-World**: SSDs for real-time physics simulations; HDDs for archiving; cloud for collaborative genomics.\n",
    "\n",
    "**Visualization**: Bar chart comparing speeds:\n",
    "```\n",
    "HDD: |---- 150 MB/s\n",
    "SSD: |----------- 1000 MB/s\n",
    "Cloud: |-- 50 MB/s (latency-dependent)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize storage speeds\n",
    "devices = ['HDD', 'SSD', 'Cloud']\n",
    "speeds = [150, 1000, 50]  # MB/s\n",
    "plt.bar(devices, speeds, color=['blue', 'green', 'orange'])\n",
    "plt.ylabel('Speed (MB/s)')\n",
    "plt.title('Storage Device Speeds (2025)')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Disk Partitioning\n",
    "\n",
    "### 2.1 What is Disk Partitioning?\n",
    "Partitioning divides a physical disk into logical sections, each functioning as a separate drive, enhancing organization and isolation.\n",
    "\n",
    "**Theory**:\n",
    "- **Purpose**: Isolates OS, data, and backups, reducing risk of total data loss.\n",
    "- **Partition Table**:\n",
    "  - **MBR**: Legacy, 4 primary partitions, 2TB max.\n",
    "  - **GPT**: Modern, 128+ partitions, exabyte support.\n",
    "- **Process**:\n",
    "  1. Initialize disk (MBR/GPT).\n",
    "  2. Allocate partitions.\n",
    "  3. Format with file system.\n",
    "  4. Mount (Linux) or assign letters (Windows).\n",
    "\n",
    "**Analogy**: A disk is a vast library; partitions are sections (e.g., fiction, science) with specific catalogs.\n",
    "\n",
    "**Real-World**: In bioinformatics, partition a 2TB SSD: 200GB for Linux (OS), 1.7TB for sequencing data, 100GB for backups.\n",
    "\n",
    "**Math**: Usable capacity = total * (1 - overhead). E.g., 2TB, 1% overhead: 2 * 0.99 = 1.98TB.\n",
    "\n",
    "**Visualization**: Bar diagram:\n",
    "```\n",
    "[200GB: Linux | ext4] | [1.7TB: Data | ext4] | [100GB: Backup | exFAT]\n",
    "```\n",
    "**Drawing Steps**:\n",
    "1. Draw a rectangle, label '2TB SSD.'\n",
    "2. Divide into three segments.\n",
    "3. Label with size, purpose, file system.\n",
    "4. Note: 'GPT, ~20GB overhead.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Practical Example: Partitioning in Linux\n",
    "**Scenario**: Set up a 500GB SSD for a physics simulation project.\n",
    "**Tool**: `gparted` (GUI partitioning).\n",
    "**Steps**:\n",
    "1. Install: `sudo apt update && sudo apt install gparted`.\n",
    "2. Launch: `sudo gparted`.\n",
    "3. Select disk (/dev/sda), choose GPT.\n",
    "4. Create:\n",
    "   - Partition 1: 100GB, ext4, label 'OS'.\n",
    "   - Partition 2: 396GB, ext4, label 'PhysicsData'.\n",
    "   - Partition 3: 4GB, swap.\n",
    "5. Apply and format.\n",
    "6. Mount: `sudo mkdir /mnt/physics && sudo mount /dev/sda2 /mnt/physics`.\n",
    "7. Auto-mount: Edit `/etc/fstab`, add: `/dev/sda2 /mnt/physics ext4 defaults 0 2`.\n",
    "**Troubleshooting**: If disk is busy, unmount: `sudo umount /dev/sda*`. Check errors: `sudo fsck /dev/sda1`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simulate partition allocation\n",
    "def allocate_partitions(total_capacity, partitions):\n",
    "    overhead = 0.01  # 1%\n",
    "    usable = total_capacity * (1 - overhead)\n",
    "    allocated = sum(size for _, size in partitions)\n",
    "    if allocated > usable:\n",
    "        return 'Error: Exceeds usable capacity'\n",
    "    return [(name, size, f'{size/total_capacity*100:.1f}%') for name, size in partitions]\n",
    "\n",
    "disk = 500  # GB\n",
    "partitions = [('OS', 100), ('PhysicsData', 396), ('Swap', 4)]\n",
    "print(allocate_partitions(disk, partitions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ["[('OS', 100, '20.0%'), ('PhysicsData', 396, '79.2%'), ('Swap', 4, '0.8%')]\n"]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAID Levels (Deep Dive)\n",
    "\n",
    "**RAID (Redundant Array of Independent Disks)** combines disks for performance, redundancy, or capacity. As of 2025, RAID evolves with SSDs, NVMe, and AI-optimized controllers, but fundamentals remain critical. RAID 5 is increasingly deprecated for large drives (>10TB) due to unrecoverable read errors (URE) during rebuilds.\n",
    "\n",
    "**Theory**:\n",
    "- **Striping**: Splits data across disks for parallel I/O.\n",
    "- **Mirroring**: Duplicates data for redundancy.\n",
    "- **Parity**: Error-correcting codes (e.g., XOR) for recovery.\n",
    "- **Logic**: Balances speed, reliability, cost.\n",
    "\n",
    "**Analogy**: RAID is a research team: Striping assigns tasks to multiple members; mirroring ensures backups; parity is a logbook to reconstruct lost work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 RAID 0 (Striping)\n",
    "**Theory**: Data is striped across disks without redundancy. Write: Split data into blocks (e.g., 64KB), distribute sequentially. Read: Parallel fetch. Failure: Entire array lost.\n",
    "\n",
    "**Math**:\n",
    "- Capacity: C = n * min(disk_size).\n",
    "- IOPS: ≈ n * single_IOPS.\n",
    "- Failure: MTTF_array = MTTF_disk / n. E.g., MTTF_disk=1e6 hours, n=3: MTTF_array ≈ 333k hours.\n",
    "- Example: 3x 1TB, single=150 MB/s: C=3TB, speed≈450 MB/s.\n",
    "\n",
    "**Real-World**: HPC for simulations (e.g., NASA fluid dynamics), backed up externally.\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "Data: ABCDEF\n",
    "Disk1: A D | Disk2: B E | Disk3: C F\n",
    "```\n",
    "**Drawing**: Three rectangles, label blocks (A, B, C), note parallel access."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simulate RAID 0 performance\n",
    "import numpy as np\n",
    "\n",
    "def raid0_performance(n_disks, single_speed):\n",
    "    return n_disks * single_speed\n",
    "\n",
    "n = 3\n",
    "speed = 150  # MB/s\n",
    "print(f'RAID 0 speed with {n} disks: {raid0_performance(n, speed)} MB/s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ["RAID 0 speed with 3 disks: 450 MB/s\n"]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RAID 1 (Mirroring)\n",
    "**Theory**: Identical data copies on all disks. Write: Broadcast to all; read: Load-balanced. Recovery: Copy from surviving disk.\n",
    "\n",
    "**Math**:\n",
    "- Capacity: C = min(disk_size).\n",
    "- Read IOPS: n * single; Write IOPS: single.\n",
    "- Reliability: P(survive) = 1 - (1 - r)^n. E.g., r=0.99, n=2: P≈0.9999.\n",
    "\n",
    "**Real-World**: Medical research mirroring MRI scans.\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "Data: ABC\n",
    "Disk1: ABC | Disk2: ABC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 RAID 5 (Striping with Parity)\n",
    "**Theory**: Stripes data with distributed parity (XOR). Write: Compute P = D1 XOR D2 ... Dn-1. Recovery: Reconstruct via XOR. Deprecated for large drives due to 'write hole' and URE risks.\n",
    "\n",
    "**Math**:\n",
    "- Capacity: C = (n-1) * min(size).\n",
    "- Parity: XOR (e.g., 3^5^7=1 in binary).\n",
    "- Example: 4x 1TB: C=3TB. Blocks 3,5,7: P=011^101^111=001. Lose 5: 011^001^111=101.\n",
    "\n",
    "**Real-World**: CERN’s LHC stores petabytes with RAID 5.\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "Stripe1: D1 D2 P(D1^D2)\n",
    "Stripe2: D3 P(D3^D4) D4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simulate RAID 5 parity\n",
    "def raid5_parity(data_blocks):\n",
    "    import numpy as np\n",
    "    return np.bitwise_xor.reduce(data_blocks)\n",
    "\n",
    "blocks = [3, 5, 7]  # Binary: 011, 101, 111\n",
    "parity = raid5_parity(blocks)\n",
    "print(f'Parity: {parity} (Binary: {bin(parity)[2:].zfill(3)})')\n",
    "# Rebuild if lose block 5\n",
    "remaining = [3, parity, 7]\n",
    "rebuilt = raid5_parity(remaining)\n",
    "print(f'Rebuilt block: {rebuilt}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ["Parity: 1 (Binary: 001)\nRebuilt block: 5\n"]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 RAID 6 and 10\n",
    "**RAID 6**: Double parity for two failures. Capacity: (n-2) * size.\n",
    "**RAID 10**: Mirrored stripes. Capacity: n/2 * size.\n",
    "**Real-World**: NOAA (RAID 6), Tesla (RAID 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Topics for Researchers\n",
    "\n",
    "**File Systems**:\n",
    "- **ZFS**: RAID-Z integrates parity, snapshots for versioning.\n",
    "- **Btrfs**: Similar, with subvolume support.\n",
    "\n",
    "**2025 Trends**:\n",
    "- NVMe RAID for ultra-fast SSDs.\n",
    "- AI-driven controllers optimize rebuilds.\n",
    "\n",
    "**Research Directions**:\n",
    "- Scalability: RAID for exabyte-scale HPC.\n",
    "- AI: Predictive failure detection.\n",
    "\n",
    "**Case Study**: CERN uses RAID 6 for 500PB of LHC data, ensuring no loss during analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tools and Software\n",
    "\n",
    "**mdadm**: Linux RAID.\n",
    "```bash\n",
    "sudo apt install mdadm\n",
    "sudo mdadm --create /dev/md0 --level=5 --raid-devices=3 /dev/sdb /dev/sdc /dev/sdd\n",
    "sudo mkfs.ext4 /dev/md0\n",
    "sudo mkdir /mnt/research\n",
    "sudo mount /dev/md0 /mnt/research\n",
    "```\n",
    "**ZFS**: `sudo apt install zfsutils-linux`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mini and Major Projects\n",
    "\n",
    "**Mini Project**: Simulate RAID 5 parity and rebuild in Python.\n",
    "**Major Project**: Design a 100TB genomics storage system with RAID 6 and ZFS, simulate failure recovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Additional Topics\n",
    "\n",
    "**LVM**: Flexible resizing.\n",
    "**Erasure Coding**: Advanced parity for cloud.\n",
    "**Research Tip**: Simulate RAID failures in VMs to study rebuild times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}